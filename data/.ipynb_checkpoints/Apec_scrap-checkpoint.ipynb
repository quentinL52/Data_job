{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7030ce07-593f-4caa-9996-e295cfbfbfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import sqlite3\n",
    "import hashlib\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddc1e39f-60c0-4e29-84e6-310301a61b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_file_storage(db_name, table_name, df):\n",
    "\n",
    "    # Connexion à la base de données SQLite\n",
    "    conn = sqlite3.connect(f\"{db_name}.db\")\n",
    "    \n",
    "    # Enregistrer le DataFrame dans la base de données\n",
    "    df.to_sql(name=table_name, con=conn, if_exists='append', index=False)\n",
    "    \n",
    "    # Fermer la connexion\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c43ccf-fd39-4f62-9e11-ccd351965fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_file_storage(user,password,host,database,table_name):\n",
    "    # Informations de connexion workbench\n",
    "    \n",
    "    user = user\n",
    "    password = password\n",
    "    host = host\n",
    "    database = database\n",
    "    \n",
    "    # Créer une chaîne de connexion\n",
    "    connection_string = f'mysql+pymysql://{user}:{password}@{host}/{database}'\n",
    "    \n",
    "    # Créer un moteur SQLAlchemy\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    # Enregistrer le DataFrame dans la base de données\n",
    "    df.to_sql(name=table_name, con=engine, if_exists='append', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb2b241c-86ad-4a6e-baba-3b1addca3bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reglage et lancement du webdriver pour selenium\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "options.add_argument(\"--headless\")  # Mode sans affichage\n",
    "options.add_argument(\"--incognito\")  # Mode incognito\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")  # Agent utilisateur\n",
    "\n",
    "service = webdriver.chrome.service.Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d528c8e2-a09d-405b-a90b-dc296e1dc8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_id(row, columns):\n",
    "    # Concaténer les valeurs des colonnes sélectionnées en une seule chaîne\n",
    "    value = ''.join(str(row[col]) for col in columns)\n",
    "    # Générer un hachage MD5 de cette chaîne\n",
    "    return hashlib.md5(value.encode()).hexdigest()\n",
    "\n",
    "def enter_apec(url):\n",
    "\n",
    "    driver.get(url + str(0))\n",
    "    \n",
    "    cookies_button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.ID, \"onetrust-reject-all-handler\"))\n",
    "    )\n",
    "    cookies_button.click()\n",
    "\n",
    "    time.sleep(1)\n",
    "    pagemax = driver.find_elements(By.CLASS_NAME, \"page-item\")[-1]\n",
    "    pagemax.click()\n",
    "    \n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"container-result\"))\n",
    "    )\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    return int(soup.find_all('a', {'class' : 'page-link'})[-1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17738058-56cc-4aed-a904-8168e6b7fe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuperation des données\n",
    "\n",
    "def multi_page_apec(nb_page_max, url):\n",
    "\n",
    "    list_href_list = []\n",
    "    \n",
    "    for page in tqdm(range(nb_page_max), desc='Pages'):\n",
    "        \n",
    "        driver.get(url + str(page))\n",
    "        \n",
    "        WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"container-result\"))\n",
    "        )\n",
    "    \n",
    "        time.sleep(1)\n",
    "        \n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        queryparamshandling_list = soup.find_all('a', {'queryparamshandling' : 'merge'})\n",
    "        list_href_list += [\"https://www.apec.fr\" + href['href'] for href in queryparamshandling_list]\n",
    "\n",
    "    \n",
    "    return list_href_list\n",
    "\n",
    "\n",
    "        \n",
    "def api_hide_apec(href_list):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "        \n",
    "    for href in tqdm(href_list, desc='Annonces'):\n",
    "        \n",
    "        id = re.findall(r'\\/([0-9]+[A-Z]+)\\?', href)[0]\n",
    "        link = f\"https://www.apec.fr/cms/webservices/offre/public?numeroOffre={id}\"\n",
    "        request = requests.get(link)\n",
    "        job_data = request.json()\n",
    "        job_df = pd.json_normalize(job_data)\n",
    "        job_df = job_df.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "        job_df['link'] = href\n",
    "        df = pd.concat([df, job_df], axis=0, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "# Nettoyage des données\n",
    "\n",
    "def clean_df_apec(df):  \n",
    "    dico_id = {\n",
    "    \n",
    "        \"idNomTypeContrat\" : {\n",
    "    \n",
    "            101888 : \"cdi\",\n",
    "            101887 : \"cdd\",\n",
    "            20053 : \"alternance\",\n",
    "            101930 : \"interim\",\n",
    "            101889 : \"interim\",\n",
    "            597137 : \"alternance\",\n",
    "            597138 : \"alternance\"\n",
    "            \n",
    "        },\n",
    "    \n",
    "        \"idNomNiveauExperience\" : {\n",
    "    \n",
    "            200269 : \"junior\",\n",
    "            597150 : \"junior\",\n",
    "            597151 : \"junior\",\n",
    "            597152 : \"junior\",\n",
    "            597153 : \"intermediaire\",\n",
    "            597154 : \"intermediaire\",\n",
    "            597155 : \"intermediaire\",\n",
    "            597156 : \"intermediaire\",\n",
    "            597157 : \"senior\",\n",
    "            597158 : \"senior\",\n",
    "            597159 : \"senior\",\n",
    "            597160 : \"senior\"            \n",
    "            \n",
    "        },\n",
    "    \n",
    "        \"idNomTeletravail\" : {\n",
    "            \n",
    "            20766 : \"ponctuel\",\n",
    "            20765 : \"partiel\",\n",
    "            20767 : \"total\",\n",
    "            20949 : \"aucun\"\n",
    "            \n",
    "        }\n",
    "    }\n",
    "    \n",
    "    rename_dico = {\n",
    "    \n",
    "        \"id\" : \"id\",\n",
    "        \"site_annonce\" : \"site_annonce\",\n",
    "        \"nomCompteEtablissement\" : \"entreprise\",\n",
    "        \"audit.dateModification\" : \"publication\",\n",
    "        \"intitule\" : \"poste\",\n",
    "        \"idNomNiveauExperience\" : \"experience\",\n",
    "        \"idNomTypeContrat\" : \"contrat\",\n",
    "        \"valeur_duree_contrat\" : \"valeur_duree_contrat\",\n",
    "        \"type_duree_contrat\" : \"type_duree_contrat\",\n",
    "        \"idNomTeletravail\" : \"teletravail\",\n",
    "        \"valeur_salaire\" : \"valeur_salaire\",\n",
    "        \"devise_salaire\" : \"devise_salaire\",\n",
    "        \"periode_salaire\" : \"periode_salaire\",        \n",
    "        \"competences\" : \"competences\",\n",
    "        \"texteHtmlProfil\" : \"profil\",\n",
    "        \"texteHtml\" : \"description\",\n",
    "        \"adresseOffre.adresseVille\" : \"ville\",\n",
    "        \"link\" : \"lien\"\n",
    "        \n",
    "    }\n",
    "    \n",
    "    dico_nan = {\n",
    "    \n",
    "        \"entreprise\" : \"inconnu\",\n",
    "        \"publication\" : np.nan,\n",
    "        \"poste\" : \"inconnu\",\n",
    "        \"experience\" : \"inconnu\",\n",
    "        \"contrat\" : \"inconnu\",\n",
    "        \"valeur_duree_contrat\" : np.nan,\n",
    "        \"type_duree_contrat\" : \"inconnu\",\n",
    "        \"teletravail\" : \"inconnu\",\n",
    "        \"valeur_salaire\" : np.nan,\n",
    "        \"devise_salaire\" : \"inconnu\",\n",
    "        \"periode_salaire\" : \"inconnu\",\n",
    "        \"competences\" : \"inconnu\",\n",
    "        \"profil\" : \"inconnu\",\n",
    "        \"description\" : \"inconnu\",\n",
    "        \"ville\" : \"inconnu\",\n",
    "    }\n",
    "    \n",
    "    df = df.apply(lambda x: x.replace({k: v for k, v in dico_id.get(x.name, {}).items()}))\n",
    "    df['audit.dateModification'] = pd.to_datetime(df['audit.dateModification']).dt.strftime('%d-%m-%Y')\n",
    "    df['texteHtml'] = df['texteHtml'].apply(lambda x: BeautifulSoup(x, \"html.parser\").text)\n",
    "    df['texteHtmlProfil'] = df['texteHtml'].apply(lambda x: BeautifulSoup(x, \"html.parser\").text)\n",
    "    df['texteHtmlEntreprise'] = df['texteHtml'].apply(lambda x: BeautifulSoup(x, \"html.parser\").text)\n",
    "    df['competences'] = df['competences'].apply(lambda x: [ x if not x else item['libelle'] for item in x])\n",
    "    df['competences'] = df['competences'].apply(lambda x: list(set(x)))\n",
    "    df['competences'] = df['competences'].apply(lambda x: ' '.join([skill.replace(\" \", \"-\") for skill in x]))\n",
    "    df['adresseOffre.adresseVille'] = df['adresseOffre.adresseVille'].apply(lambda x: x if pd.isna(x) else re.findall(r'^[a-zA-Z]+\\b', x)[0])\n",
    "    df['site_annonce'] = \"apec\"\n",
    "    df['id'] = df.apply(lambda row: generate_id(row, ['nomCompteEtablissement','intitule','idNomTypeContrat','adresseOffre.adresseVille']), axis=1)\n",
    "    df['valeur_salaire'] = df['salaireTexte'].apply(lambda x: np.nan if x == \"a négocier\" else int(re.findall(r'[0-9]+', x )[0] + \"000\"))\n",
    "    df['devise_salaire'] = df['salaireTexte'].apply(lambda x: np.nan if x == \"a négocier\" else re.findall(r'(?:£|\\$|€)', x )[0])\n",
    "    df['periode_salaire'] = df['salaireTexte'].apply(lambda x: np.nan if x == \"a négocier\" else re.findall(r'.*?(\\w+)$', x )[0])\n",
    "    df['periode_salaire'] = df['periode_salaire'].str.replace('annuel', 'annee')    \n",
    "    df['valeur_duree_contrat'] = df.apply(lambda row: row['dureeContrat'] if 'dureeContrat' in row.index else np.nan, axis=1)\n",
    "    df['type_duree_contrat'] = df.apply(lambda row: 'mensuel' if 'dureeContrat' in row.index else np.nan, axis=1)\n",
    "    filtre_columns = [v for k,v in rename_dico.items()]\n",
    "    df = df.rename(columns=rename_dico)[filtre_columns]\n",
    "    df = df.fillna(value=dico_nan)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd1b01ab-19eb-4157-aedb-b68dfb39bf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_apec():\n",
    "    url = \"https://www.apec.fr/candidat/recherche-emploi.html/emploi?motsCles=data&salaireMinimum=20&salaireMaximum=200&typesConvention=143684&typesConvention=143685&typesConvention=143686&typesConvention=143687&anciennetePublication=101850&page=\"\n",
    "    nb_page_max = enter_apec(url)\n",
    "    href_list = multi_page_apec(nb_page_max, url)\n",
    "    \n",
    "    df_not_clean = api_hide_apec(href_list)\n",
    "    \n",
    "    df_clean = clean_df_apec(df_not_clean)\n",
    "    db_file_storage('apec', 'df_clean', df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f68523a-f053-4ee8-8c9f-1dcb08d3483d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pages: 100%|███████████████████████████████████████████████████████████████████████████| 30/30 [00:46<00:00,  1.55s/it]\n",
      "Annonces: 100%|██████████████████████████████████████████████████████████████████████| 598/598 [11:15<00:00,  1.13s/it]\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_10980\\2744405460.py:132: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  df['texteHtmlProfil'] = df['texteHtml'].apply(lambda x: BeautifulSoup(x, \"html.parser\").text)\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_10980\\2744405460.py:133: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  df['texteHtmlEntreprise'] = df['texteHtml'].apply(lambda x: BeautifulSoup(x, \"html.parser\").text)\n"
     ]
    }
   ],
   "source": [
    "main_apec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896c722b-c227-47a0-8fba-f91ef20217bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
